{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6181f65e",
   "metadata": {},
   "source": [
    "## Final code to convert this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc01de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "\n",
    "INPUT_FILE = \"paddy_disease.jsonl\"       # your source file\n",
    "OUTPUT_FILE = \"paddy_disease_llava.json\" # Official LLaVA format\n",
    "\n",
    "def parse_qa_block(text):\n",
    "    \"\"\"\n",
    "    Parses Q/A blocks like 'Q1: ... A1: ...' or 'Q: ... A: ...'\n",
    "    into a list of (question, answer) tuples.\n",
    "    \"\"\"\n",
    "    lines = [line.strip() for line in text.split(\"\\n\") if line.strip()]\n",
    "    qa_pairs = []\n",
    "    q, a = None, None\n",
    "    for line in lines:\n",
    "        if line.lower().startswith(\"q\"):\n",
    "            if q and a:\n",
    "                qa_pairs.append((q, a))\n",
    "                a = None\n",
    "            q = line.split(\":\", 1)[1].strip()\n",
    "        elif line.lower().startswith(\"a\"):\n",
    "            a = line.split(\":\", 1)[1].strip()\n",
    "    if q and a:\n",
    "        qa_pairs.append((q, a))\n",
    "    return qa_pairs\n",
    "\n",
    "def convert_to_llava_format():\n",
    "    output_records = []\n",
    "    \n",
    "    with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            record = json.loads(line)\n",
    "\n",
    "            conversations = []\n",
    "\n",
    "            # 1. Description first\n",
    "            if record.get(\"description\"):\n",
    "                conversations.append({\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": \"<image>\\nDescribe the image.\"\n",
    "                })\n",
    "                conversations.append({\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": record[\"description\"].strip()\n",
    "                })\n",
    "\n",
    "            # 2. Multi-turn QA\n",
    "            if record.get(\"multi_turn_conversation\"):\n",
    "                for q, a in parse_qa_block(record[\"multi_turn_conversation\"]):\n",
    "                    conversations.append({\"from\": \"human\", \"value\": q})\n",
    "                    conversations.append({\"from\": \"gpt\", \"value\": a})\n",
    "\n",
    "            # 3. Simple QA\n",
    "            if record.get(\"simple_qa\"):\n",
    "                for q, a in parse_qa_block(record[\"simple_qa\"]):\n",
    "                    conversations.append({\"from\": \"human\", \"value\": q})\n",
    "                    conversations.append({\"from\": \"gpt\", \"value\": a})\n",
    "\n",
    "            output_records.append({\n",
    "                \"id\": str(uuid.uuid4()),\n",
    "                \"image\": record[\"image_path\"],\n",
    "                \"conversations\": conversations\n",
    "            })\n",
    "\n",
    "    # Write array to JSON file\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(output_records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"Converted {len(output_records)} records to {OUTPUT_FILE} in official format\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    convert_to_llava_format()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
